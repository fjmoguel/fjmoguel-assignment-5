{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "x1HFVUccajj_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "occ5wjlXajkA"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # TODO: Implement the fit method\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        # TODO: Implement the predict method\n",
        "        distances = self.compute_distance(self.X_train, X)\n",
        "        predictions = []\n",
        "        for i in range(X.shape[0]):\n",
        "            k_indices = np.argsort(distances[:, i])[:self.k]\n",
        "            k_nearest_labels = self.y_train[k_indices].astype(int)  # Cast to int\n",
        "            prediction = np.argmax(np.bincount(k_nearest_labels))\n",
        "            predictions.append(prediction)\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def compute_distance(self, X_train, X_test):\n",
        "        # TODO: Implement distance computation based on self.distance_metric\n",
        "        # Hint: Use numpy operations for efficient computation\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return np.sqrt(np.sum(X_train**2, axis=1).reshape(-1, 1) +np.sum(X_test**2, axis=1) - 2 * np.dot(X_train, X_test.T))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return np.sum(np.abs(X_train[:, np.newaxis] - X_test), axis=2)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown distance metric: {self.distance_metric}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "_Fiuy97gajkB"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "    # TODO: Implement data preprocessing\n",
        "    # Handle categorical variables, scale features, etc.\n",
        "    train_data = train_data.drop(['CustomerId', 'Surname'], axis=1)\n",
        "    test_data = test_data.drop(['CustomerId', 'Surname'], axis=1)\n",
        "\n",
        "    train_data = pd.get_dummies(train_data, columns=['Geography', 'Gender'], drop_first=True)\n",
        "    test_data = pd.get_dummies(test_data, columns=['Geography', 'Gender'], drop_first=True)\n",
        "\n",
        "    test_data = test_data.reindex(columns=train_data.columns.drop('Exited'), fill_value=0)\n",
        "\n",
        "    X_train = train_data.drop('Exited', axis=1).values\n",
        "    y_train = train_data['Exited'].values\n",
        "    X_test = test_data.values\n",
        "    for i in range(X_train.shape[1]):\n",
        "        mean = np.mean(X_train[:, i])\n",
        "        std = np.std(X_train[:, i])\n",
        "        if std == 0:\n",
        "            std = 1\n",
        "        X_train[:, i] = (X_train[:, i] - mean) / std\n",
        "        X_test[:, i] = (X_test[:, i] - mean) / std\n",
        "    return X_train, y_train, X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "vH8sxAIDajkB"
      },
      "outputs": [],
      "source": [
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    # TODO: Implement cross-validation\n",
        "    # Compute ROC AUC scores\n",
        "    n = len(y)\n",
        "    indices = np.arange(n)\n",
        "    unique_classes, y_indices = np.unique(y, return_inverse=True)\n",
        "    fold_indices = [[] for _ in range(n_splits)]\n",
        "    for c in unique_classes:\n",
        "        class_indices = indices[y == c]\n",
        "        np.random.shuffle(class_indices)\n",
        "        for i, idx in enumerate(np.array_split(class_indices, n_splits)):\n",
        "            fold_indices[i].extend(idx)\n",
        "    auc_scores = []\n",
        "    for i, val_idx in enumerate(fold_indices):\n",
        "        train_idx = np.setdiff1d(indices, val_idx)\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        knn.fit(X_train, y_train)\n",
        "        \n",
        "        y_pred_proba = []\n",
        "        distances = knn.compute_distance(X_train, X_val)\n",
        "        for j in range(X_val.shape[0]):\n",
        "            k_indices = np.argsort(distances[:, j])[:knn.k]\n",
        "            k_nearest_labels = y_train[k_indices]\n",
        "            prob_class_1 = np.sum(k_nearest_labels == 1) / knn.k\n",
        "            y_pred_proba.append(prob_class_1)\n",
        "\n",
        "        y_pred_proba = np.array(y_pred_proba)\n",
        "        \n",
        "        if len(np.unique(y_val)) > 1:\n",
        "            auc = roc_auc(y_val, y_pred_proba)\n",
        "            auc_scores.append(abs(auc))\n",
        "        else:\n",
        "            auc_scores.append(0.5)\n",
        "    \n",
        "    return auc_scores\n",
        "\n",
        "def roc_auc(y_true, y_pred_proba):\n",
        "    pos_label = 1\n",
        "    thresholds = np.sort(np.unique(y_pred_proba))\n",
        "    tpr_list, fpr_list = [], []\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "        tp = np.sum((y_true == pos_label) & (y_pred == pos_label))\n",
        "        fp = np.sum((y_true != pos_label) & (y_pred == pos_label))\n",
        "        fn = np.sum((y_true == pos_label) & (y_pred != pos_label))\n",
        "        tn = np.sum((y_true != pos_label) & (y_pred != pos_label))\n",
        "\n",
        "        tpr = tp / (tp + fn) if tp + fn > 0 else 0\n",
        "        fpr = fp / (fp + tn) if fp + tn > 0 else 0\n",
        "\n",
        "        tpr_list.append(tpr)\n",
        "        fpr_list.append(fpr)\n",
        "\n",
        "    tpr_list = np.array(tpr_list)\n",
        "    fpr_list = np.array(fpr_list)\n",
        "\n",
        "    auc = np.trapz(tpr_list, fpr_list)\n",
        "    return auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "tvGViAQrajkC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores: [0.8794511677326211, 0.8576503724990676, 0.8624633489633067, 0.875579419621862, 0.8623729276396089]\n",
            "Best K: 27, Best Distance Metric: manhattan, Best AUC: 0.904740291527725\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "# Create and evaluate model\n",
        "knn = KNN(k=5, distance_metric='euclidean')\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(X, y, knn)\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "\n",
        "# TODO: hyperparameters tuning\n",
        "best_auc = 0\n",
        "best_k = 1\n",
        "best_distance = 'euclidean'\n",
        "\n",
        "# Loop over both 'euclidean' and 'manhattan' metrics\n",
        "for distance_metric in ['euclidean', 'manhattan']:\n",
        "    for k in range(15, 28):\n",
        "        knn = KNN(k=k, distance_metric=distance_metric)\n",
        "        auc_scores = cross_validate(X, y, knn)\n",
        "        avg_auc = np.mean(auc_scores)\n",
        "        if avg_auc > best_auc:\n",
        "            best_auc = avg_auc\n",
        "            best_k = k\n",
        "            best_distance = distance_metric\n",
        "\n",
        "print(f\"Best K: {best_k}, Best Distance Metric: {best_distance}, Best AUC: {best_auc}\")\n",
        "\n",
        "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "knn = KNN(k=best_k, distance_metric=best_distance)\n",
        "knn.fit(X, y)\n",
        "test_predictions = []\n",
        "distances_test = knn.compute_distance(knn.X_train, X_test)\n",
        "\n",
        "for j in range(X_test.shape[0]):\n",
        "    k_indices = np.argsort(distances_test[:, j])[:knn.k]\n",
        "    k_nearest_labels = knn.y_train[k_indices]\n",
        "    prob_class_1 = np.sum(k_nearest_labels == 1) / knn.k\n",
        "    test_predictions.append(prob_class_1)\n",
        "\n",
        "# Save test predictions\n",
        "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
